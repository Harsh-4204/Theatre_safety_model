{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import pandas as pd\n",
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "Jsrc4EGmUKnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained models\n",
        "age_model = load_model(\"/content/age_detection_model.keras\")\n",
        "emotion_model = load_model(\"/content/emotion_detection_model.keras\")\n",
        "\n",
        "# Emotion labels\n",
        "emotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n"
      ],
      "metadata": {
        "id": "RSAXeOjbUSKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_data(age, emotion, allowed):\n",
        "    \"\"\"\n",
        "    Save the detected data into a CSV file.\n",
        "    \"\"\"\n",
        "    data = {\n",
        "        \"Timestamp\": [datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")],\n",
        "        \"Age\": [age],\n",
        "        \"Emotion\": [emotion],\n",
        "        \"Allowed\": [allowed]\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    with open(\"age_emotion_data.csv\", mode='a', index=False) as f:\n",
        "        df.to_csv(f, header=f.tell() == 0)  # Add header only if file is new\n"
      ],
      "metadata": {
        "id": "v3Hzp1t0UrMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_age(predicted_age_class):\n",
        "    \"\"\"\n",
        "    Decode the predicted age class into an approximate age range.\n",
        "    \"\"\"\n",
        "    return predicted_age_class * 15  # Age intervals of 15 (e.g., 0-14, 15-29, ...)\n"
      ],
      "metadata": {
        "id": "VYPXldzUUvNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_and_display(frame):\n",
        "    \"\"\"\n",
        "    Detect faces and predict age/emotion for each detected face.\n",
        "    \"\"\"\n",
        "    # Load Haarcascade for face detection\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        # Preprocess face for the models\n",
        "        face = frame[y:y+h, x:x+w]\n",
        "        face_input = cv2.resize(face, (198, 198)) / 255.0\n",
        "        face_input = np.expand_dims(face_input, axis=0)\n",
        "\n",
        "        # Predict age\n",
        "        age_probs = age_model.predict(face_input)\n",
        "        predicted_age_class = age_probs.argmax()\n",
        "        predicted_age = decode_age(predicted_age_class)\n",
        "\n",
        "        # Check \"Not allowed\" criteria\n",
        "        if predicted_age < 13 or predicted_age > 60:\n",
        "            # Mark with red rectangle and display \"Not allowed\"\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
        "            cv2.putText(frame, \"Not allowed\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
        "            save_data(predicted_age, None, \"No\")\n",
        "        else:\n",
        "            # Predict emotion\n",
        "            emotion_probs = emotion_model.predict(face_input)\n",
        "            predicted_emotion = emotion_labels[emotion_probs.argmax()]\n",
        "\n",
        "            # Mark with green rectangle and display age/emotion\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f\"Age: {predicted_age}, Emotion: {predicted_emotion}\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "            save_data(predicted_age, predicted_emotion, \"Yes\")\n",
        "\n",
        "    return frame\n"
      ],
      "metadata": {
        "id": "oKhmU24WUy8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Run the real-time age and emotion detection.\n",
        "    \"\"\"\n",
        "    # Open webcam\n",
        "    cap = cv2.VideoCapture(1)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Detect and display\n",
        "        processed_frame = detect_and_display(frame)\n",
        "        cv2.imshow(\"Age and Emotion Detection\", processed_frame)\n",
        "\n",
        "        # Press 'q' to exit\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "MSttsZsIU2q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty CSV file with headers\n",
        "df = pd.DataFrame(columns=[\"Timestamp\", \"Age\", \"Emotion\", \"Allowed\"])\n",
        "df.to_csv(\"age_emotion_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "ON2loQTqU57t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_capture = cv2.VideoCapture(1)\n"
      ],
      "metadata": {
        "id": "2mLsZjJAU_iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the captured image\n",
        "try:\n",
        "    filename = take_photo()\n",
        "    print(f\"Saved to {filename}\")\n",
        "\n",
        "    # Read the image\n",
        "    img = cv2.imread(filename)\n",
        "    img_resized = cv2.resize(img, (198, 198))  # Resize to the model's expected input size\n",
        "    img_preprocessed = img_resized / 255.0\n",
        "    img_input = np.expand_dims(img_preprocessed, axis=0)\n",
        "\n",
        "    # Predict age\n",
        "    age_pred = age_model.predict(img_input)\n",
        "    print(f\"Age Prediction Output: {age_pred}\")  # Debugging output\n",
        "    age_category = np.argmax(age_pred)\n",
        "    print(f\"Age Category: {age_category}\")  # Debugging output\n",
        "\n",
        "    age_ranges = ['0-14', '15-29','30-44','45-59','60-74','75-89','90-104','105-119']  # Update with your actual intervals\n",
        "    if age_category < len(age_ranges):  # Check if the predicted category is valid\n",
        "        predicted_age = age_ranges[age_category]\n",
        "    else:\n",
        "        predicted_age = \"Unknown\"\n",
        "\n",
        "    # Predict emotion if within allowed age range\n",
        "    if age_category == 0 or age_category > 3:  # Adjust based on your intervals\n",
        "        message = \"Not allowed\"\n",
        "        emotion = None\n",
        "    else:\n",
        "        emotion_pred = emotion_model.predict(img_input)\n",
        "        print(f\"Emotion Prediction Output: {emotion_pred}\")  # Debugging output\n",
        "        emotion_labels = ['Happy', 'Sad', 'Neutral']  # Replace with your emotion labels\n",
        "        if len(emotion_pred) > 0:  # Ensure there is an output to handle\n",
        "            emotion = emotion_labels[np.argmax(emotion_pred)]\n",
        "        else:\n",
        "            emotion = \"Unknown\"\n",
        "        message = f\"Emotion: {emotion}\"\n",
        "\n",
        "    # Display results\n",
        "    print(f\"Predicted Age: {predicted_age}\")\n",
        "    print(f\"Message: {message}\")\n",
        "    if emotion:\n",
        "        print(f\"Emotion: {emotion}\")\n",
        "\n",
        "    # Save to CSV\n",
        "    entry_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    data = {'Age': [predicted_age], 'Emotion': [emotion], 'Entry Time': [entry_time]}\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv('theatre_log.csv', mode='a', header=False, index=False)\n",
        "    print(\"Data saved to theatre_log.csv\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "rAfA30cYXX67",
        "outputId": "0282193f-1888-40ce-8b69-0408f5a8d4c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const capture = document.createElement('button');\n",
              "            capture.textContent = 'Capture';\n",
              "            div.appendChild(capture);\n",
              "\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "            await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to photo.jpg\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Age Prediction Output: [[1.1037527e-01 3.3849061e-02 6.1395075e-02 2.6629084e-01 3.7139511e-01\n",
            "  1.2570420e-01 2.7346157e-02 3.4003051e-03 2.4392168e-04]]\n",
            "Age Category: 4\n",
            "Predicted Age: 60-74\n",
            "Message: Not allowed\n",
            "Data saved to theatre_log.csv\n"
          ]
        }
      ]
    }
  ]
}